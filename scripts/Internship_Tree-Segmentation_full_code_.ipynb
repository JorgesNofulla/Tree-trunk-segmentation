{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228c23f8-c981-4664-a8dd-8f02cf40abbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libraries and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d2c6a1-d483-44c8-a489-bad108e282a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import laspy as lp\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial import KDTree, ckdtree\n",
    "from matplotlib.cm import tab20 as cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5507e750-035b-48fa-8c4f-50f061b05a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "\n",
    "    index = None\n",
    "    position = None\n",
    "    paths = []\n",
    "    network = None\n",
    "    vec = None\n",
    "    linked_to = None\n",
    "    treeID = None\n",
    "\n",
    "    def __init__(self, index, position):\n",
    "        self.index = index\n",
    "        self.position = position\n",
    "\n",
    "    def add_path(self, path):\n",
    "        self.paths = np.append(self.paths, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "640b9618-577c-4542-a6af-7aed57fde1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Path:\n",
    "\n",
    "    index = None\n",
    "    points = []\n",
    "    network = None\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def add_point(self, this_point):\n",
    "        self.points = np.append(self.points, this_point)\n",
    "\n",
    "    def all_points_position(self):\n",
    "        points_pos = np.c_[[],[],[]]\n",
    "        for point in self.points:\n",
    "            points_pos = np.append(points_pos, np.c_[point.position], axis=0)\n",
    "        return points_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b791bb-2994-4706-a16b-819381b027f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    index = None\n",
    "    paths = []\n",
    "    points = []\n",
    "    top = None\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def add_path(self, path):\n",
    "        self.paths = np.append(self.paths, path)\n",
    "        path.network = self\n",
    "        for point in path.points:\n",
    "            point.network = self\n",
    "        self.points = np.append(self.points, path.points)\n",
    "\n",
    "    def size(self):\n",
    "        points = np.array(())\n",
    "        for path in self.paths:\n",
    "            for point in path.points:\n",
    "                points = np.append(points, point)\n",
    "        return len(points)\n",
    "\n",
    "    def all_paths(self):\n",
    "        all_paths = np.array(())\n",
    "        for path in self.paths:\n",
    "            all_paths = np.append(all_paths, path.index)\n",
    "        return all_paths\n",
    "\n",
    "    def all_points_position(self):\n",
    "        points_pos = np.array(())\n",
    "        for point in self.points:\n",
    "            points_pos = np.append(points_pos, point.position)\n",
    "        points_pos = np.reshape(points_pos, (-1, 3))\n",
    "        return points_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d2cf8-6b5a-4c27-bb0e-2230a2532db7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Insert the parameters for the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6a28c8-4f82-44bb-8f88-a8f0dbe99d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the desired Las file here.\n",
    "las_file = lp.file.File('../Sample_test.las', mode=\"r\")\n",
    "# name  your output\n",
    "output_las = \"Output_file.las\"\n",
    "# Parameters (all values are in meters)\n",
    "r = 4  # radius of the search spehere for the initial clustering\n",
    "radius = 0.8  # the radius on which we count the point density in x and y for each point (the parameter used for local maxima calculation)\n",
    "window_size = 6  # the size of the search window for local maxima in each cluster\n",
    "max_distance = 0.8  # the delineated trunks radius\n",
    "restrict_d = 6  # the minimum eucledian distance that 2 peaks of the same cluster can have\n",
    "small_clusters = 100  # the size of the small custers we suspect as outliers (won't be deleted, they will just merge with a nearby big cluster if there is any, else they will be taken as individual clusters)\n",
    "small_outliers = 30  # OPTIONAL! The minimal cluster size to be allowed as a tree. Deleting every cluster below this value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7bc6a5-cbd7-4e35-940d-6af58cb22dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK THE END OF THE CODE TO CHOOSE THE TYPE OF THE OUTPUT !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e832f2-80ba-4e9f-9f26-8323959b0c5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Load and Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a445b5ed-46da-4d6e-91e6-dc1c5b4d94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "# concatenate the file coordinates\n",
    "coord = np.c_[las_file.x, las_file.y, las_file.z]\n",
    "\n",
    "# turnk the coordinates into full integers\n",
    "x_new = (las_file.x).astype('int')\n",
    "y_new = (las_file.y).astype('int')\n",
    "z_new = (las_file.z).astype('int')\n",
    "\n",
    "# Reduce the data, get a flat voxel index. Lowers the number of points feed to the algorithm.\n",
    "new_coords = x_new + y_new * x_new.max() + z_new * y_new.max() * x_new.max()\n",
    "_, sl = np.unique(new_coords, return_index=True)\n",
    "coord = coord[sl,:]\n",
    "\n",
    "# sort the coordinates by z value\n",
    "coord_sorted = coord[coord[:, 2].argsort()]\n",
    "position = coord_sorted\n",
    "\n",
    "# points is a list of \"point\" class for each set of coordinates\n",
    "# i= index/position and coord_sorted as a position\n",
    "for i in range(len(coord_sorted)):\n",
    "    i = Point(i, coord_sorted[i])\n",
    "    points.append(i)\n",
    "# create an ordered array with the size of remaning coord\n",
    "index = np.arange(len(coord))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8bebd-7aec-42d2-942f-2a09f0226260",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Find centroids of point clusters and tree peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05081a96-5242-49ab-985e-7c3085919ea4",
   "metadata": {},
   "source": [
    "1. A collection of points in 3D space is given, with a manually input radius value.\n",
    "2. The code finds groups of points that are within the radius of each other, and it computes their group centroids.\n",
    "3. For each group, it finds the point with the highest Z-value (i.e., the top of the tree), and links it to the centroid.\n",
    "4. The code outputs the index of the closest point to the centroid for each group, and whether each point is the highest point of its group (i.e., at the top of the tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b034c-223c-4ab8-8101-f7662de52feb",
   "metadata": {},
   "source": [
    "Reasons why the code runs fast\n",
    "1. Using list comprehension to find the neighbors with a higher z value rather than creating a new numpy array and using numpy's boolean indexing to find these neighbors.\n",
    "2. Checking for cases where a point has no neighbors within radius r first to avoid unnecessary calculations.\n",
    "3. Initializing the links and centroids arrays to the same length as the position array with zeros to avoid needing to use np.append() inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1c083f-9851-45fa-8dfc-bb22c6a091db",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = np.zeros(len(position), dtype=int)\n",
    "centroids = np.zeros((len(position), 3))\n",
    "has_parent = np.zeros(len(position), dtype=bool)\n",
    "\n",
    "# Find all points within distance r of point(s) x\n",
    "tree = scipy.spatial.cKDTree(position)\n",
    "nn = tree.query_ball_point(position, r)\n",
    "\n",
    "# Loop over all points\n",
    "for i, this_nn in enumerate(nn):\n",
    "    # If the point has no neighbors within radius r, it is a tree peak\n",
    "    if len(this_nn) == 1:\n",
    "        links[i] = i\n",
    "        centroids[i] = position[i]\n",
    "        has_parent[i] = True\n",
    "    # If the point has at least one neighbor within radius rlink_nn\n",
    "    else:\n",
    "        # Find all neighbors with a higher z value\n",
    "        upper_nnbs = [j for j in this_nn if position[j, 2] > position[i, 2]]\n",
    "        # If there are no such neighbors, the point is a tree peak\n",
    "        if not upper_nnbs:\n",
    "            links[i] = i\n",
    "            centroids[i] = position[i]\n",
    "            has_parent[i] = True\n",
    "        # If there are any neighbors with a higher z value\n",
    "        else:\n",
    "            # Calculate the centroid of the group of neighbors\n",
    "            c = np.mean(position[upper_nnbs], axis=0)\n",
    "            centroids[i] = c\n",
    "            # Calculate the distances between each neighbor and the centroid\n",
    "            dist = scipy.spatial.distance.cdist(position[upper_nnbs], [c],\n",
    "                                                metric=\"euclidean\")\n",
    "            # Find the neighbor closest to the centroid and store its index as a link\n",
    "            links[i] = upper_nnbs[np.argmin(dist)]\n",
    "\n",
    "# Convert links to integer type\n",
    "link_nn = links.astype(int)\n",
    "has_parent = has_parent.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641304f-6874-475f-9a89-309fe9847293",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Label the points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b6cec2-e0af-4e16-92b7-5258bef2040a",
   "metadata": {},
   "source": [
    "1. For each point, the code checks if it has already been assigned to a path.\n",
    "2. If not, it creates a new path and adds the current point to it.\n",
    "3. It then follows the links created in Part 1 to add more points to the path, until it reaches a point with no parent (i.e., at the top of the tree), at which point it ends the path.\n",
    "4. If the code encounters a point that is already in a path, it creates a new network that includes both the new path and the existing path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68b019e2-7870-46e9-92c0-608b29d7c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = []\n",
    "all_paths = []\n",
    "for p in points:\n",
    "    current_idx = p.index\n",
    "\n",
    "    if len(points[current_idx].paths) == 0:\n",
    "        end = False\n",
    "\n",
    "        # initialize new path\n",
    "        new_path = Path(len(all_paths))  # len paths as index\n",
    "        all_paths.append(new_path)\n",
    "\n",
    "        # add first point to the path\n",
    "        new_path.add_point(points[current_idx])\n",
    "        points[current_idx].add_path(new_path)\n",
    "\n",
    "        # append path\n",
    "        while end == False:\n",
    "\n",
    "            # point has a parent\n",
    "            if has_parent[current_idx] != 1:\n",
    "\n",
    "                # make link\n",
    "                points[current_idx].linked_to = points[link_nn[current_idx]]\n",
    "\n",
    "                if len(points[current_idx].linked_to.paths) == 0:\n",
    "\n",
    "                    # not in path\n",
    "                    points[current_idx].linked_to.add_path(new_path)\n",
    "                    new_path.add_point(points[current_idx].linked_to)\n",
    "                    current_idx = link_nn[current_idx]\n",
    "\n",
    "                else:\n",
    "                    # in path\n",
    "                    points[current_idx].linked_to.network.add_path(new_path)\n",
    "                    points[current_idx].add_path(new_path)\n",
    "                    points[current_idx].linked_to.add_path(new_path)\n",
    "                    end = True\n",
    "\n",
    "            # point has no parent\n",
    "            # make network, end path\n",
    "            else:\n",
    "                points[current_idx].linked_to = points[current_idx]\n",
    "                # init new network\n",
    "                new_network = Network(len(networks))  # len networks as index\n",
    "                new_network.add_path(new_path)  # path and points are assigned to the network\n",
    "                new_network.top = current_idx\n",
    "                new_network.points = new_path.points  # add points to the network\n",
    "                networks.append(new_network)\n",
    "                points[current_idx].network = new_network\n",
    "                end = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168f332-463f-4241-8226-86155803b201",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Get the labels array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b5694fc-fd07-463c-a9dc-e8900a804e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new np array to extract and store all our individual tree labels from\n",
    "labels = np.zeros(len(points))\n",
    "centroids = np.array(())\n",
    "size = np.array(())\n",
    "# extract the label value from class network to our new built array\n",
    "for p in points:\n",
    "    labels[p.index] = p.network.index\n",
    "labels = labels.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f8ca0-ebb0-4291-92a5-79e7b4ef367a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remove all the outlier clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad3b541-34ab-4a67-b75e-04f4a4756d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_test = np.column_stack((position, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b23e757-95ae-4e02-aeb5-9f2854d512c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each cluster label\n",
    "labels_new = array_test[:, 3]\n",
    "array = array_test[:, 0:3]\n",
    "unique, counts = np.unique(labels_new, return_counts=True)\n",
    "\n",
    "# Create a dictionary to store the count of each label\n",
    "label_count = dict(zip(unique, counts))\n",
    "\n",
    "# Initialize an empty list to store the indices of the large clusters\n",
    "large_cluster_indices = []\n",
    "\n",
    "# Iterate through the cluster labels\n",
    "for i, label in enumerate(labels_new):\n",
    "    # If the label corresponds to a large cluster, add the index to the list\n",
    "    if label_count.get(label, 0) >= 10:\n",
    "        large_cluster_indices.append(i)\n",
    "\n",
    "# Use the indices of the large clusters to create a new array\n",
    "array_test = array[large_cluster_indices, :]\n",
    "\n",
    "# Add the labels as the last column of the new array\n",
    "array_test = np.column_stack((array_test, labels_new[large_cluster_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0dec85-96de-4f2e-98b9-628e124f9424",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fix the small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5114be52-b644-49c1-8e62-856bc85facca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the array for the \"fix small clusters\" code\n",
    "labels_2 = array_test[:, 3].astype('int')\n",
    "labels33, point_count33 = np.unique(labels_2, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4153088c-218e-43a3-bbaf-b434857abe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterating_array = []\n",
    "for i in range(len(labels33)):\n",
    "    if point_count33[i] <= small_clusters:\n",
    "        iterating_array.append(labels33[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4656378-ea93-4c26-acfe-4daa1e8a9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centroids of all clusters in the dataset\n",
    "all_centroids = []\n",
    "all_labs=[]\n",
    "for label in np.unique(array_test[:, 3]):\n",
    "    centroid = array_test[array_test[:, 3] == label, :2].mean(axis=0)\n",
    "    all_centroids.append(centroid)\n",
    "    all_labs.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e783db14-9efd-4968-a525-609f97d281f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the pairs of the closest clusters\n",
    "\n",
    "tree1 = KDTree(all_centroids)\n",
    "\n",
    "labels_nn = []\n",
    "for i in range(len(all_labs)):\n",
    "    point_cent = all_centroids[i]\n",
    "    dist, idx = tree1.query(point_cent, k=2)\n",
    "    closest_idx = idx[1] if idx[0] == i else idx[0]\n",
    "    labels_nn.append([all_labs[i], all_labs[closest_idx ]])\n",
    "\n",
    "# filter the list so it contains only the small clusters that we will fix\n",
    "filtered_list = [x for x in labels_nn if int(x[0]) in iterating_array]\n",
    "array_test2 = array_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4084d21-4ada-4426-b71f-0ed50e9c0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other parameters for tree merging\n",
    "diff_height = 1.5  # the difference in height between 2 clusters very close to each other (this is the parameter to take care of branches that are classified as a separate cluster)\n",
    "branch_dist = 0.8  # the max distance a branch clsuter can be from the main tree\n",
    "min_dist_tree = 1  # the max distance of 2 clusters to be checked if they are the same tree\n",
    "\n",
    "for i in filtered_list:\n",
    "    coord_xy = array_test2[array_test2[:, 3] == i[0]]\n",
    "    coord_xy2 = array_test2[array_test2[:, 3] == i[1]]\n",
    "    wk = distance.cdist(coord_xy[:, :2], coord_xy2[:, :2], 'euclidean')\n",
    "    z = abs(coord_xy[:, 2:3].min()-coord_xy[:, 2:3].min())\n",
    "    kk = array_test2[:, 2][array_test2[:, 3] == i[1]]\n",
    "    z = abs(coord_xy[:, 2:3].min() - kk.min())\n",
    "    if len(array_test2[array_test2 == i[0]]) < (small_clusters/2) and wk.min() < min_dist_tree :\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    if wk.min() < branch_dist and z > diff_height:\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    if len(array_test2[array_test2 == i[0]]) < small_clusters and wk.min() < min_dist_tree/2:\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    coord_xy = []\n",
    "    coord_xy2 = []\n",
    "    wk = []\n",
    "    ind = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd44d0-d676-4b26-ac40-64760713e39d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optional! Delete small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec470d9-21b0-42e3-9d9e-2cca447c5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each cluster label\n",
    "labels_new = array_test[:, 3]\n",
    "array = array_test[:, 0:3]\n",
    "unique, counts = np.unique(labels_new, return_counts=True)\n",
    "\n",
    "# Create a dictionary to store the count of each label\n",
    "label_count = dict(zip(unique, counts))\n",
    "\n",
    "# Initialize an empty list to store the indices of the large clusters\n",
    "large_cluster_indices = []\n",
    "\n",
    "# Iterate through the cluster labels\n",
    "for i, label in enumerate(labels_new):\n",
    "    # If the label corresponds to a large cluster, add the index to the list\n",
    "    if label_count.get(label, 0) >= small_outliers:\n",
    "        large_cluster_indices.append(i)\n",
    "\n",
    "# Use the indices of the large clusters to create a new array\n",
    "array_test = array[large_cluster_indices, :]\n",
    "\n",
    "# Add the labels as the last column of the new array\n",
    "array_test = np.column_stack((array_test, labels_new[large_cluster_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80a909-e3a0-4e57-8ae4-87e6d990798f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. Get the number of points in buffer per point (the local maxima column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515d54e6-f1b5-4212-8f30-5cfd79d7b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "points = array_test[:, :2]\n",
    "\n",
    "# Create KDTree from points\n",
    "kd_tree = KDTree(points)\n",
    "\n",
    "# Array to store the number of points in the buffer for each point\n",
    "count = np.zeros(len(points), dtype=int)\n",
    "\n",
    "# Loop over each point and find points in the buffer\n",
    "for i, p in enumerate(points):\n",
    "    idx = kd_tree.query_ball_point(p, radius)\n",
    "    count[i] = len(idx) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d42d2-aeeb-4541-9f28-52c085f99289",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. Find the tree trunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec8a3c8a-3954-45c4-9e07-cf8743d27c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the full array\n",
    "full_array = np.column_stack((array_test, count))\n",
    "\n",
    "\n",
    "def cluster_local_maxima1(full_array, window_size, max_distance, restrict_d):\n",
    "    # get the unique label of tree clusters\n",
    "    unique_clusters = np.unique(full_array[:, 3])\n",
    "    current_label = 1\n",
    "    labels = np.zeros(full_array.shape[0], dtype=np.int64)\n",
    "    full_array = np.column_stack((full_array, labels))\n",
    "    iteration=0\n",
    "    # Iterate through every single tree cluster separately\n",
    "    for cluster_id in unique_clusters:\n",
    "        peaks1=[]\n",
    "        dist_peaks = 100\n",
    "        # Form an array for the cluster of this iteration\n",
    "        kot_arr = full_array[full_array[:, 3] == cluster_id]\n",
    "        x1 = kot_arr[:, 0]\n",
    "        y1 = kot_arr[:, 1]\n",
    "        z1 = kot_arr[:, 2]\n",
    "        p1 = kot_arr[:, 4]\n",
    "        labels_k = kot_arr[:, 5]\n",
    "        # Now we iterate through each point of the cluster of this iteration\n",
    "        for i in range(len(kot_arr)):\n",
    "            # We form a seach window around each point of the cluster\n",
    "            x_min = x1[i] - window_size\n",
    "            x_max = x1[i] + window_size\n",
    "            y_min = y1[i] - window_size\n",
    "            y_max = y1[i] + window_size\n",
    "            in_window = np.bitwise_and(x1 >= x_min, x1 <= x_max)\n",
    "            in_window = np.bitwise_and(in_window, np.bitwise_and(y1 >= y_min, y1 <= y_max))\n",
    "            in_window = np.bitwise_and(in_window, kot_arr[:, 3] == cluster_id)\n",
    "\n",
    "            # Calculate and save the distances between the local maximas we find.\n",
    "            if len(peaks1) > 0:\n",
    "                this_point = [x1[i],y1[i]]\n",
    "                peak_array = np.array(peaks1)\n",
    "                this_point = np.array(this_point)\n",
    "                this_point = this_point.reshape(1, 2)\n",
    "                dist_peaks = distance.cdist(peak_array, this_point, 'euclidean')\n",
    "                \n",
    "            # We find the local maximas for each window\n",
    "            # Then we restric every local maximas that are way too close with each other with the parameter \"restrict_d\"\n",
    "            # Then the local maximas with an accepted distace between each other are relabeld as a unique number for each unique tree.\n",
    "            if np.max(p1[in_window]) == p1[i] and np.min(dist_peaks) > restrict_d:\n",
    "                peaks1.append([x1[i], y1[i]])\n",
    "                points_to_label = np.argwhere(np.logical_and(np.abs(x1-x1[i]) <= max_distance, np.abs(y1-y1[i]) <= max_distance))\n",
    "                points_to_label = points_to_label.flatten()\n",
    "                if labels_k[i] == 0:\n",
    "                    labels_k[points_to_label] = current_label\n",
    "                    current_label += 1\n",
    "                else:\n",
    "                    labels_k[points_to_label] = labels_k[i]\n",
    "\n",
    "        # we create a new array with the new labels for trunks\n",
    "        new_2 = np.c_[x1,y1,z1,labels_k]\n",
    "        if iteration == 0:\n",
    "            final_result = new_2\n",
    "        else:\n",
    "            final_result = np.vstack((final_result, new_2))\n",
    "        iteration=1\n",
    "\n",
    "    return final_result\n",
    "\n",
    "\n",
    "Final_labels = cluster_local_maxima1(full_array, window_size, max_distance, restrict_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af3dfae7-36f4-4e9b-84e9-708f0e08896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 23 trees in this area\n"
     ]
    }
   ],
   "source": [
    "# Get the number of trees in this las file\n",
    "tree_count = np.unique(Final_labels[:, 3])\n",
    "print(\"there are\", len(tree_count), \"trees in this area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0787fdd4-1697-4da9-b735-ac408e086863",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save the trunk Point Cloud as a new Las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c7d3b07-0469-45ef-95bd-d40428c553f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = Final_labels\n",
    "c = Final_labels[:, 3]\n",
    "\n",
    "vals = np.linspace(0, 1, 100)\n",
    "np.random.shuffle(vals)\n",
    "cmap = plt.cm.colors.ListedColormap(plt.cm.tab20(vals))\n",
    "header = lp.header.Header()\n",
    "header.data_format_id = 2\n",
    "new_las = lp.file.File(output_las, mode='w', header=header)\n",
    "new_las.header.scale = [0.01, 0.01, 0.01]\n",
    "new_las.header.offset = [lb[:, 0].min(), lb[:, 1].min(), lb[:, 2].min()]\n",
    "new_las.x = lb[:, 0]\n",
    "new_las.y = lb[:, 1]\n",
    "new_las.z = lb[:, 2]\n",
    "new_las.pt_src_id = c.astype('uint16')\n",
    "new_las.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964afb50-fa13-4d98-ba37-cb7323a43d10",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ALTERNATIVE OUTPUT\n",
    "# Getting only one point(centroid) in X and Y for each tree trunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39e6b6d7-1f7f-41ab-8530-8cc461afc348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1031848f-e9f6-4560-9db5-b0b715450a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCentroid_tree = np.unique(Final_labels[:, 3])[1:]\\ncentroids_coord = {}\\n\\n# Iterate through each cluster and find the centroid\\nfor label in Centroid_tree:\\n    cluster_points = Final_labels[Final_labels[:, 3] == label][:, :2]\\n    centroid = np.mean(cluster_points, axis=0)\\n    centroids_coord[label] = centroid\\n\\n#print(centroids_coord)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Centroid_tree = np.unique(Final_labels[:, 3])[1:]\n",
    "centroids_coord = {}\n",
    "\n",
    "# Iterate through each cluster and find the centroid\n",
    "for label in Centroid_tree:\n",
    "    cluster_points = Final_labels[Final_labels[:, 3] == label][:, :2]\n",
    "    centroid = np.mean(cluster_points, axis=0)\n",
    "    centroids_coord[label] = centroid\n",
    "\n",
    "#print(centroids_coord)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be783bb4-66a4-485f-b269-e284651d3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cd57a99-e402-4007-baab-ec4c1dcc5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique cluster labels excluding label zero\n",
    "Centroid_tree = np.unique(Final_labels[:, 3])[1:]\n",
    "# Initialize an empty list to store the centroids for each cluster\n",
    "centroids_array  = []\n",
    "\n",
    "# Iterate through each cluster and find the centroid\n",
    "for label in Centroid_tree:\n",
    "    cluster_points = Final_labels[Final_labels[:, 3] == label][:, :2]\n",
    "    centroid = list(np.mean(cluster_points, axis=0))\n",
    "    centroids_array.append([centroid[0], centroid[1], label])\n",
    "\n",
    "centroids_array = np.array(centroids_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a05d69-e024-4872-bf34-4c23fd234009",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save only the tree centroids as 2D points (LAS FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be2a11fa-dd5e-4f31-a92b-e1e52873325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = \"Output_centroids_only.las\"\n",
    "z_value = np.zeros(centroids_array.shape[0], dtype=np.int64)\n",
    "lab = centroids_array\n",
    "c = centroids_array[:, 2]\n",
    "\n",
    "vals = np.linspace(0, 1, 100)\n",
    "np.random.shuffle(vals)\n",
    "cmap = plt.cm.colors.ListedColormap(plt.cm.tab20(vals))\n",
    "header = lp.header.Header()\n",
    "header.data_format_id = 2\n",
    "new_las = lp.file.File(output_name, mode='w', header=header)\n",
    "new_las.header.scale = [0.01, 0.01,0.01]\n",
    "new_las.header.offset = [lab[:, 0].min(), lab[:, 1].min(),z_value.min()]\n",
    "new_las.x = lab[:, 0]\n",
    "new_las.y = lab[:, 1]\n",
    "new_las.z = z_value\n",
    "new_las.pt_src_id = c.astype('uint16')\n",
    "new_las.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec598e-1c28-4a5b-81a6-857e98c4e56f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save only the tree centroids as 2D points (SHAPEFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7da509d-d268-4c22-9169-ae366b4b6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapefile\n",
    "# Create a new shapefile\n",
    "sf = shapefile.Writer(\"Output_centroids_only.las\", shapeType=shapefile.POINT)\n",
    "\n",
    "# Define the fields for the shapefile\n",
    "sf.field(\"label\", \"N\")\n",
    "\n",
    "# Iterate through each row of the array and add a point to the shapefile\n",
    "for row in centroids_array:\n",
    "    # Extract the x, y, and label values from the row\n",
    "    x, y, label = row\n",
    "\n",
    "    # Add a point to the shapefile with the x and y coordinates\n",
    "    sf.point(x, y)\n",
    "\n",
    "    # Set the attributes for the point\n",
    "    sf.record(label)\n",
    "\n",
    "# Save and close the shapefile\n",
    "sf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92966ff4-f432-4e02-975a-63adf9b4ca32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
